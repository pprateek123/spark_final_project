{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries and starting spark session\n",
    "from os import environ\n",
    "import yaml\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('solutions_final')\\\n",
    "        .config('spark.driver.extraClassPath','/usr/lib/jvm/java-11-openjdk-amd64/lib/postgresql-42.6.0.jar')\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your YAML file\n",
    "yaml_file_path = 'config.yaml'\n",
    "\n",
    "# Read the YAML file and parse it into a Python dictionary\n",
    "with open(yaml_file_path, 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary funcitons from spark\n",
    "from pyspark.sql.functions import col,row_number, sum ,format_number,desc,year,month,lag,when ,cast,avg,substring,lit, length,expr,concat_ws, to_date,udf\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as f\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING PART\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#reading csv from local folder\n",
    "\n",
    "data_path = \"./data/revised_final.csv\"  \n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "#loading goods_classifiation \n",
    "data_path = \"./data/goods_classification.csv\"  \n",
    "df_goods = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "data_path = \"./data/country_classification.csv\"  \n",
    "df_country = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "data_path = \"./data/services_classification.csv\"  \n",
    "df_services = spark.read.csv(data_path, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----+------------+------------+-------------+------+\n",
      "|time_ref|account|code|country_code|product_type|        value|status|\n",
      "+--------+-------+----+------------+------------+-------------+------+\n",
      "|  202306|Exports|  00|          AE|       Goods| 2.82028909E8|     F|\n",
      "|  202306|Exports|  00|          AG|       Goods|     351919.0|     F|\n",
      "|  202306|Exports|  00|          AI|       Goods|      84762.0|     F|\n",
      "|  202306|Exports|  00|          AL|       Goods|       3463.0|     F|\n",
      "|  202306|Exports|  00|          AM|       Goods|     679586.0|     F|\n",
      "|  202306|Exports|  00|          AO|       Goods|     464583.0|     F|\n",
      "|  202306|Exports|  00|          AR|       Goods|    5943055.0|     F|\n",
      "|  202306|Exports|  00|          AS|       Goods|  1.1622992E7|     F|\n",
      "|  202306|Exports|  00|          AT|       Goods|  1.1202334E7|     F|\n",
      "|  202306|Exports|  00|          AU|       Goods|2.272665701E9|     F|\n",
      "|  202306|Exports|  00|          AW|       Goods|     362396.0|     F|\n",
      "|  202306|Exports|  00|          AZ|       Goods|    5816857.0|     F|\n",
      "|  202306|Exports|  00|          BB|       Goods|    8464598.0|     F|\n",
      "|  202306|Exports|  00|          BD|       Goods| 1.77083931E8|     F|\n",
      "|  202306|Exports|  00|          BE|       Goods|  9.4312051E7|     F|\n",
      "|  202306|Exports|  00|          BF|       Goods|      36757.0|     F|\n",
      "|  202306|Exports|  00|          BG|       Goods|    3697081.0|     F|\n",
      "|  202306|Exports|  00|          BH|       Goods|   2.272435E7|     F|\n",
      "|  202306|Exports|  00|          BJ|       Goods|     507511.0|     F|\n",
      "|  202306|Exports|  00|          BM|       Goods|     529761.0|     F|\n",
      "+--------+-------+----+------------+------------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- time_ref: integer (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- product_type: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2111267"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##exploring the main df\n",
    "df.show()\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing time_ref column to string appeding month and changing it into date format \n",
    "\n",
    "df = df.withColumn(\"time_ref\", col(\"time_ref\").cast(\"string\"))\n",
    "\n",
    "df = df.withColumn(\"time_ref\", concat_ws(\"/\", substring(col(\"time_ref\"), 1, 4), substring(col(\"time_ref\"), 5, 2), lit('30')))\n",
    "df = df.withColumn(\"time_ref\", to_date(col(\"time_ref\"), \"yyyy/MM/dd\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## filtering unnecessary data and  changing the length of goods column for ease in join\n",
    "\n",
    "df = df.filter(df['country_code'] != 'TOT')\n",
    "\n",
    "df = df.filter(df['country_code'] != 'TOT (BoP basis)')\n",
    "\n",
    "df = df.filter(df['country_code'] != 'TOT (OMT FOB)')\n",
    "df = df.filter(df['country_code'] != 'TOT (OMT CIF)')\n",
    "df = df.filter(df['country_code'] != 'TOT (OMT VFD)')\n",
    "\n",
    "\n",
    "\n",
    "df = df.withColumn(\"code\",\n",
    "    when((col(\"product_type\") == \"Goods\") & (length(col(\"code\")) == 4), substring(col(\"code\"), 1, 2))\n",
    "    .when((col(\"product_type\") == \"Goods\") & (length(col(\"code\")) == 3), substring(col(\"code\"), 1, 1))\n",
    "    .otherwise(col(\"code\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## renaming column from df_goods for ease \n",
    "\n",
    "df_goods = df_goods.withColumnRenamed('Level_1','code')\\\n",
    "        .withColumnRenamed('Level_1_desc','goods_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/13 14:05:07 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#writing file in parquet format in local  \n",
    "df.write.format(\"parquet\")\\\n",
    "    .mode('overwrite')\\\n",
    "    .options(compression=\"snappy\")\\\n",
    "    .save(\"./data_cleaned/revised_final_cleaned/cleaned_revised.parquet\")\n",
    "\n",
    "\n",
    "\n",
    "df_goods.coalesce(1).write.format(\"parquet\").mode(\"overwrite\").\\\n",
    "options(compression='snappy').\\\n",
    "save(\"./data_cleaned/goods_cleaned/cleaned_goods.parquet\")\n",
    "df_services.coalesce(1).write.format(\"parquet\").mode(\"overwrite\").\\\n",
    "options(compression='snappy').\\\n",
    "save(\"./data_cleaned/services_cleaned/cleaned_sevices.parquet\")\n",
    "df_country.coalesce(1).write.format(\"parquet\").mode(\"overwrite\").\\\n",
    "options(compression='snappy').\\\n",
    "save(\"./data_cleaned/countries_cleaned/cleaned_countries.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#writing files to the prostgres table \n",
    "\n",
    "df.write.format('jdbc').options(url='jdbc:postgresql://localhost:5432/postgres',driver = 'org.postgresql.Driver', dbtable = 'cleaned_data', user=config['postgres'][\"user\"],password=config['postgres'][\"password\"] ).mode('overwrite')\n",
    "df_goods.write.format('jdbc').options(url='jdbc:postgresql://localhost:5432/postgres',driver = 'org.postgresql.Driver', dbtable = 'cleaned_goods', user=config['postgres'][\"user\"],password=pg_password ).mode('overwrite')\n",
    "df_services.write.format('jdbc').options(url='jdbc:postgresql://localhost:5432/postgres',driver = 'org.postgresql.Driver', dbtable = 'cleaned_services', user=config['postgres'][\"user\"],password=pg_password ).mode('overwrite')\n",
    "df_country.write.format('jdbc').options(url='jdbc:postgresql://localhost:5432/postgres',driver = 'org.postgresql.Driver', dbtable = 'cleaned_countries', user=config['postgres'][\"user\"],password=pg_password ).mode('overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTIONS PART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the cleaned tables from the postgres database\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "connection_properties = {\n",
    "    \"user\": pg_user,\n",
    "    \"password\": pg_password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "table_name = \"cleaned_data\"\n",
    "table_goods = \"cleaned_goods\"\n",
    "table_services = \"cleaned_services\"\n",
    "table_countries = \"cleaned_countries\"\n",
    "\n",
    "df = spark.read \\\n",
    "    .jdbc(url=jdbc_url, table=table_name, properties=connection_properties)\n",
    "df_goods = spark.read \\\n",
    "    .jdbc(url=jdbc_url, table=table_goods, properties=connection_properties)\n",
    "\n",
    "df_services = spark.read \\\n",
    "    .jdbc(url=jdbc_url, table=table_services, properties=connection_properties)\n",
    "\n",
    "df_countries = spark.read \\\n",
    "    .jdbc(url=jdbc_url, table=table_countries, properties=connection_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "#### Trend analysis of the two countries which has the highest transactIons with new zealand. Increasing and decreasing trends of the sum of the transaction in each quarter month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[time_ref: date, account: string, code: string, country_code: string, product_type: string, value: double, status: string]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caching for faster loads\n",
    "# only cached the main df because that is the largest file\n",
    "\n",
    "df.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 2 countries are :  CN : 847,920,192,569.20 and AU : 761,016,231,517.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/13 14:05:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+------------------+------------------+------------------+-------------------+------------------+--------+---------+\n",
      "|year|month|            sum($)|         sum($)_au|            lag($)|         lag_au($)|      difference($)|  difference_au($)|  change|change_au|\n",
      "+----+-----+------------------+------------------+------------------+------------------+-------------------+------------------+--------+---------+\n",
      "|2014|    9|30,149,345,938,005|33,248,377,325,064|32,078,321,144,240|30,005,845,954,049| -1,928,975,206,235| 3,242,531,371,015|Decrease| Increase|\n",
      "|2014|   12|37,084,530,234,212|35,309,257,882,759|30,149,345,938,005|33,248,377,325,064|  6,935,184,296,207| 2,060,880,557,695|Increase| Increase|\n",
      "|2015|    3|35,467,973,908,136|31,201,448,464,812|37,084,530,234,212|35,309,257,882,759| -1,616,556,326,076|-4,107,809,417,947|Decrease| Decrease|\n",
      "|2015|    6|33,182,651,329,464|31,174,360,965,062|35,467,973,908,136|31,201,448,464,812| -2,285,322,578,672|   -27,087,499,750|Decrease| Decrease|\n",
      "|2015|    9|37,515,060,607,995|33,921,927,075,906|33,182,651,329,464|31,174,360,965,062|  4,332,409,278,531| 2,747,566,110,844|Increase| Increase|\n",
      "|2015|   12|42,124,513,748,760|34,505,529,632,608|37,515,060,607,995|33,921,927,075,906|  4,609,453,140,765|   583,602,556,702|Increase| Increase|\n",
      "|2016|    3|38,452,087,044,000|31,695,938,532,378|42,124,513,748,760|34,505,529,632,608| -3,672,426,704,760|-2,809,591,100,230|Decrease| Decrease|\n",
      "|2016|    6|37,260,607,943,702|31,335,067,251,072|38,452,087,044,000|31,695,938,532,378| -1,191,479,100,298|  -360,871,281,306|Decrease| Decrease|\n",
      "|2016|    9|36,953,105,075,259|33,227,853,435,588|37,260,607,943,702|31,335,067,251,072|   -307,502,868,443| 1,892,786,184,516|Decrease| Increase|\n",
      "|2016|   12|43,007,005,677,438|34,723,597,756,813|36,953,105,075,259|33,227,853,435,588|  6,053,900,602,179| 1,495,744,321,225|Increase| Increase|\n",
      "|2017|    3|40,926,173,258,734|32,519,835,017,932|43,007,005,677,438|34,723,597,756,813| -2,080,832,418,704|-2,203,762,738,881|Decrease| Decrease|\n",
      "|2017|    6|43,161,959,390,616|32,981,432,805,654|40,926,173,258,734|32,519,835,017,932|  2,235,786,131,882|   461,597,787,722|Increase| Increase|\n",
      "|2017|    9|41,171,007,126,056|36,056,523,324,192|43,161,959,390,616|32,981,432,805,654| -1,990,952,264,560| 3,075,090,518,538|Decrease| Increase|\n",
      "|2017|   12|53,247,411,335,420|37,283,526,456,220|41,171,007,126,056|36,056,523,324,192| 12,076,404,209,364| 1,227,003,132,028|Increase| Increase|\n",
      "|2018|    3|45,509,936,783,506|33,946,193,788,200|53,247,411,335,420|37,283,526,456,220| -7,737,474,551,914|-3,337,332,668,020|Decrease| Decrease|\n",
      "|2018|    6|47,993,021,514,571|34,560,162,303,832|45,509,936,783,506|33,946,193,788,200|  2,483,084,731,065|   613,968,515,632|Increase| Increase|\n",
      "|2018|    9|49,180,304,679,345|37,748,074,074,018|47,993,021,514,571|34,560,162,303,832|  1,187,283,164,774| 3,187,911,770,186|Increase| Increase|\n",
      "|2018|   12|62,739,552,347,082|38,396,645,993,736|49,180,304,679,345|37,748,074,074,018| 13,559,247,667,737|   648,571,919,718|Increase| Increase|\n",
      "|2019|    3|52,569,061,937,248|35,049,044,478,380|62,739,552,347,082|38,396,645,993,736|-10,170,490,409,834|-3,347,601,515,356|Decrease| Decrease|\n",
      "|2019|    6|55,737,901,779,504|34,822,393,322,989|52,569,061,937,248|35,049,044,478,380|  3,168,839,842,256|  -226,651,155,391|Increase| Decrease|\n",
      "+----+-----+------------------+------------------+------------------+------------------+-------------------+------------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/13 14:05:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## top 2 countries with the highest number of transactions \n",
    "df_highest = df.groupBy('country_code').agg(sum(col('value')).alias('sum($)'))\n",
    "df_highest= df_highest.orderBy(desc(col('sum($)')))\n",
    "df_highest = df_highest.withColumn('sum($)', format_number(col('sum($)'),2)).limit(2)\n",
    "print(\"the top 2 countries are : \",df_highest.collect()[0][0],\":\",df_highest.collect()[0][1],\"and\" , df_highest.collect()[1][0],':',df_highest.collect()[1][1] )\n",
    "\n",
    "## only taking the transaction of the top 2 countires (filter first)\n",
    "df_cn = df.filter(col('country_code')=='CN')\n",
    "df_au = df.filter(col('country_code')=='AU')\n",
    "\n",
    "##renaming columns\n",
    "columns = df_au.columns\n",
    "for i in range(len(columns)):\n",
    "    df_au = df_au.withColumnRenamed(columns[i], columns[i]+'_au')\n",
    "\n",
    "## combining both countries transactions horizontally\n",
    "df_joined = df_cn.join(df_au,df_cn['time_ref']==df_au['time_ref_au'],'inner')\n",
    "\n",
    "#extracting month and year \n",
    "df_joined = df_joined.withColumn(\"year\", year(\"time_ref\")).withColumn(\"month\", month(\"time_ref\"))\\\n",
    "                     .withColumnRenamed('value','value($)')\\\n",
    "                     .withColumnRenamed('value_au','value($)_au')\n",
    "\n",
    "\n",
    "## selecting only the required columns \n",
    "df_joined_req_col = df_joined.select('year','month','value($)','value($)_au')\n",
    "\n",
    "\n",
    "\n",
    "df_joined_req_col = df_joined_req_col.groupBy('year','month')\\\n",
    "                        .agg(sum(col('value($)')).alias('sum($)'),sum(col('value($)_au')).alias('sum($)_au'))\n",
    "\n",
    "\n",
    "#window\n",
    "window_spec = Window.orderBy(\"year\",\"month\")\n",
    "\n",
    "df_joined_req_col = df_joined_req_col.withColumn('lag($)',lag(col('sum($)'),1).over(window_spec))\\\n",
    "                                     .withColumn('lag_au($)',lag(col('sum($)_au'),1).over(window_spec))\n",
    "df_joined_req_col = df_joined_req_col.na.drop()\n",
    "\n",
    "#difference and trend analysis\n",
    "df_final = df_joined_req_col.withColumn('difference($)',col('sum($)')-col('lag($)'))\\\n",
    "                            .withColumn('difference_au($)',col('sum($)_au')-col('lag_au($)'))\n",
    "\n",
    "\n",
    "df_final = df_final.withColumn('change', when(col('difference($)')>0,\"Increase\").otherwise('Decrease'))\\\n",
    "                    .withColumn('change_au',when(col('difference_au($)')>0,'Increase').otherwise('Decrease'))\n",
    "\n",
    "\n",
    "df_final_formatted = df_final.select('*')\n",
    "\n",
    "## to show in human readable form\n",
    "for i in range(len(df_final.columns)-4):\n",
    "    df_final_formatted = df_final_formatted.withColumn(df_final.columns[i+2],format_number(col(df_final.columns[i+2]),0))\n",
    "\n",
    "df_final_formatted.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/13 14:05:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/09/13 14:05:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#writing the table to postgres \n",
    "df_final.write.format('jdbc').options(url='jdbc:postgresql://localhost:5432/postgres',driver = 'org.postgresql.Driver', dbtable = 'task1', user='postgres',password='postgres').mode('overwrite').save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : \n",
    "#### TO calculate the most sold(Exported) good to each country in each year from NewZealand and  Find how deviated is it from the mean transaction  of that particular good. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+---------+----------------+--------------------+-------------------+\n",
      "|year|country_code|    value|mean_value_goods|      goods_category|deviation from mean|\n",
      "+----+------------+---------+----------------+--------------------+-------------------+\n",
      "|2014|          VA|  44817.0|       136561.55|Apparel and cloth...|          -91744.55|\n",
      "|2014|          MW|  36363.0|       542332.18|Optical, photogra...|         -505969.18|\n",
      "|2014|          PS|  96501.0|       701522.83|Vegetables and ce...|         -605021.83|\n",
      "|2014|          LI|   1571.0|       542332.18|Optical, photogra...|         -540761.18|\n",
      "|2014|          CV|   1447.0|       333540.86|Electrical machin...|         -332093.86|\n",
      "|2014|          SO|   8400.0|       542332.18|Optical, photogra...|         -533932.18|\n",
      "|2014|          CC|  11088.0|      2167770.96|Natural, cultured...|        -2156682.96|\n",
      "|2014|          GL|   3344.0|        65929.13|Arms and ammuniti...|          -62585.13|\n",
      "|2014|          ZB|    6.0E7|      7298100.43|New Zealand misce...|      5.270189957E7|\n",
      "|2014|          MD| 351046.0|      2438945.96|Fish and crustace...|        -2087899.96|\n",
      "|2014|          ZB|    6.0E7|      7298100.43|New Zealand misce...|      5.270189957E7|\n",
      "|2014|          BJ|1197522.0|      2438945.96|Fish and crustace...|        -1241423.96|\n",
      "|2014|          KN|  63016.0|      9745989.32|Meat and edible m...|        -9682973.32|\n",
      "|2014|          BA|  40071.0|      2438945.96|Fish and crustace...|        -2398874.96|\n",
      "|2014|          SM|   1548.0|       410770.22|Vehicles; other t...|         -409222.22|\n",
      "|2014|          BY| 211451.0|      2438945.96|Fish and crustace...|        -2227494.96|\n",
      "|2014|          ZS|8805878.0|      7298100.43|New Zealand misce...|         1507777.57|\n",
      "|2014|          LR| 323354.0|      2438945.96|Fish and crustace...|        -2115591.96|\n",
      "|2014|          ZB|    6.0E7|      7298100.43|New Zealand misce...|      5.270189957E7|\n",
      "|2014|          FO|1060092.0|      9745989.32|Meat and edible m...|        -8685897.32|\n",
      "+----+------------+---------+----------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "#finding just the sold goods\n",
    "df_sold = df.filter(col('account')=='Exports')\n",
    "df_sold = df_sold.filter(col('product_type')=='Goods')\n",
    "\n",
    "#extracting year\n",
    "df_each_year = df_sold.withColumn('year', year('time_ref'))\n",
    "\n",
    "\n",
    "## finding out which country has imported max sum of  good in a year\n",
    "df_result =df_each_year.groupBy('country_code','year').agg(f.max(col('value')).alias('value'))\n",
    "\n",
    "#joining the main table with teh grouped one to find out which country imported how much in a particular year along with other details\n",
    "df_joined = df_each_year.join(df_result , on = ['country_code','value','year'] , how = 'inner')\n",
    "df_joined  = df_joined.dropDuplicates()\n",
    "df_joined = df_joined.filter(col('code')!=00)\n",
    "df_joined = df_joined.orderBy('country_code','year')\n",
    "\n",
    "\n",
    "## to find out the mean (average value) of each category of goods. \n",
    "df_goods_avg = df_each_year.groupBy('code').agg(avg(col('value')).alias('mean_value_goods'))\n",
    "df_goods_avg = df_goods_avg.withColumn('mean_value_goods', f.round(col('mean_value_goods'),2))\n",
    "\n",
    "df_goods_unique = df_goods.groupBy('goods_category').agg(f.max('code').alias('code'))\n",
    "df_joined_avg = df_goods_avg.join(df_goods_unique , on = 'code', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "## joining the average for each good and previous table\n",
    "\n",
    "df_joined_final =  df_joined.join(df_joined_avg, on = 'code', how = 'inner')\n",
    "\n",
    "\n",
    "\n",
    "##percent deviation from mean \n",
    "\n",
    "df_deviation = df_joined_final.withColumn('deviation from mean', f.round(col('value')-col('mean_value_goods'),2))\n",
    "\n",
    "df_deviation.select('year','country_code','value','mean_value_goods','goods_category','deviation from mean').orderBy('year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "##writing thi dataframe to postgres\n",
    "df_deviation.write.format('jdbc').options(url='jdbc:postgresql://localhost:5432/postgres',driver = 'org.postgresql.Driver', dbtable = 'task2', user='postgres',password='postgres').mode('overwrite').save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopping the spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_final",
   "language": "python",
   "name": "venv_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
